#!/usr/bin/env python3
"""
Ollamaåƒåœ¾åˆ†ç±»AIé—®ç­”åŠ©æ‰‹å¯åŠ¨è„šæœ¬
"""

import sys
import os
import subprocess
import time
import requests
from PyQt5.QtWidgets import QApplication, QMessageBox

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from knowledge_base import KnowledgeBaseWindow

def check_ollama_service():
    """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=3)
        return response.status_code == 200
    except:
        return False

def start_ollama_service():
    """å°è¯•å¯åŠ¨OllamaæœåŠ¡"""
    try:
        print("ğŸš€ æ­£åœ¨å¯åŠ¨OllamaæœåŠ¡...")
        # åœ¨åå°å¯åŠ¨OllamaæœåŠ¡
        subprocess.Popen(["ollama", "serve"], 
                         stdout=subprocess.DEVNULL, 
                         stderr=subprocess.DEVNULL)
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        for i in range(10):
            time.sleep(1)
            if check_ollama_service():
                print("âœ… OllamaæœåŠ¡å¯åŠ¨æˆåŠŸ")
                return True
            print(f"â³ ç­‰å¾…æœåŠ¡å¯åŠ¨... ({i+1}/10)")
        
        print("âŒ OllamaæœåŠ¡å¯åŠ¨è¶…æ—¶")
        return False
        
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°Ollamaï¼Œè¯·å…ˆå®‰è£…Ollama")
        print("ğŸ’¡ å®‰è£…æ–¹æ³•:")
        print("   Windows: è®¿é—® https://ollama.ai ä¸‹è½½å®‰è£…")
        print("   macOS: brew install ollama")
        print("   Linux: curl -fsSL https://ollama.ai/install.sh | sh")
        return False
    except Exception as e:
        print(f"âŒ å¯åŠ¨OllamaæœåŠ¡å¤±è´¥: {e}")
        return False

def check_models():
    """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ¨¡å‹"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            if models:
                print(f"ğŸ“‹ æ‰¾åˆ° {len(models)} ä¸ªå·²å®‰è£…çš„æ¨¡å‹")
                return True
            else:
                print("âš ï¸  æœªæ‰¾åˆ°å·²å®‰è£…çš„æ¨¡å‹")
                print("ğŸ’¡ è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…æ¨¡å‹:")
                print("   ollama pull deepseek-chat")
                return False
        return False
    except:
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– åƒåœ¾åˆ†ç±»AIé—®ç­”åŠ©æ‰‹ (Ollamaç‰ˆ)")
    print("=" * 50)
    
    # æ£€æŸ¥OllamaæœåŠ¡
    if not check_ollama_service():
        print("ğŸ” OllamaæœåŠ¡æœªè¿è¡Œï¼Œå°è¯•å¯åŠ¨...")
        if not start_ollama_service():
            print("\nâŒ æ— æ³•å¯åŠ¨OllamaæœåŠ¡")
            print("ğŸ’¡ è¯·æ‰‹åŠ¨å¯åŠ¨OllamaæœåŠ¡:")
            print("   1. æ‰“å¼€ç»ˆç«¯")
            print("   2. è¿è¡Œ: ollama serve")
            print("   3. é‡æ–°è¿è¡Œæ­¤ç¨‹åº")
            sys.exit(1)
    
    # æ£€æŸ¥æ¨¡å‹
    if not check_models():
        print("\nâŒ æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹")
        print("ğŸ’¡ è¯·å®‰è£…æ¨¡å‹åé‡è¯•:")
        print("   ollama pull deepseek-chat")
        sys.exit(1)
    
    print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼Œå¯åŠ¨åº”ç”¨...")
    
    # å¯åŠ¨GUIåº”ç”¨
    app = QApplication(sys.argv)
    
    try:
        window = KnowledgeBaseWindow()
        window.show()
        
        print("ğŸ‰ åƒåœ¾åˆ†ç±»AIé—®ç­”åŠ©æ‰‹å·²å¯åŠ¨ï¼")
        print("ğŸ’¡ ä½¿ç”¨æç¤º:")
        print("   - ç‚¹å‡»å·¦ä¾§å¸¸è§é—®é¢˜å¿«é€Ÿæé—®")
        print("   - åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥è‡ªå®šä¹‰é—®é¢˜")
        print("   - æŸ¥çœ‹å³ä¸Šè§’è¿æ¥çŠ¶æ€")
        
        sys.exit(app.exec_())
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨åº”ç”¨å¤±è´¥: {e}")
        QMessageBox.critical(None, "å¯åŠ¨å¤±è´¥", f"æ— æ³•å¯åŠ¨åº”ç”¨:\n{e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
